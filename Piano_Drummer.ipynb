{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Piano_Drummer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Piano Drummer (ver. 1.0)\n",
        "\n",
        "***\n",
        "\n",
        "Powered by tegridy-tools: https://github.com/asigalov61/tegridy-tools\n",
        "\n",
        "***\n",
        "\n",
        "Credit for GPT2-RGA code used in this colab goes out @ Sashmark97 https://github.com/Sashmark97/midigen and @ Damon Gwinn https://github.com/gwinndr/MusicTransformer-Pytorch\n",
        "\n",
        "***\n",
        "\n",
        "WARNING: This complete implementation is a functioning model of the Artificial Intelligence. Please excercise great humility, care, and respect. https://www.nscai.gov/\n",
        "\n",
        "***\n",
        "\n",
        "#### Project Los Angeles\n",
        "\n",
        "#### Tegridy Code 2022\n",
        "\n",
        "***"
      ],
      "metadata": {
        "id": "jvEB1_NCaV0I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title nvidia-smi gpu check\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "1J28fQ8XYNU7",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VD0w2tsYA4XV",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Install all dependencies (run only once per session)\n",
        "\n",
        "!git clone https://github.com/asigalov61/tegridy-tools\n",
        "\n",
        "!pip install torch\n",
        "\n",
        "!pip install tqdm\n",
        "!pip install matplotlib\n",
        "!pip install torch-summary\n",
        "\n",
        "!apt install fluidsynth #Pip does not work for some reason. Only apt works\n",
        "!pip install midi2audio\n",
        "!pip install pretty_midi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Import all needed modules\n",
        "\n",
        "print('Loading needed modules. Please wait...')\n",
        "import os\n",
        "import random\n",
        "from collections import OrderedDict\n",
        "import copy\n",
        "from tqdm import tqdm\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torchsummary import summary\n",
        "\n",
        "if not os.path.exists('/content/Dataset'):\n",
        "    os.makedirs('/content/Dataset')\n",
        "\n",
        "print('Loading TMIDIX module...')\n",
        "os.chdir('/content/tegridy-tools/tegridy-tools')\n",
        "import TMIDIX\n",
        "\n",
        "os.chdir('/content/tegridy-tools/tegridy-tools')\n",
        "from GPT2RGAX import *\n",
        "\n",
        "from midi2audio import FluidSynth\n",
        "import pretty_midi\n",
        "import librosa.display\n",
        "from IPython.display import Audio\n",
        "\n",
        "os.chdir('/content/')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "9foSOfZ1BApU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download MIDI dataset"
      ],
      "metadata": {
        "id": "y_qXToJuFySI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<iframe src=\"https://onedrive.live.com/embed? width=\"98\" height=\"120\" frameborder=\"0\" scrolling=\"no\"></iframe>"
      ],
      "metadata": {
        "id": "DklsoUSwbOmw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Rock-Piano Dataset\n",
        "!wget --no-check-certificate -O 'Rock-Piano.zip' \"https://onedrive.live.com/download?cid=8A0D502FC99C608F&resid=8A0D502FC99C608F%2118570&authkey=APv5HBxyoa5LAPo\"\n",
        "!unzip Rock-Piano.zip"
      ],
      "metadata": {
        "cellView": "form",
        "id": "mVM-8iULLxXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Process"
      ],
      "metadata": {
        "id": "oVZb72xiCO1Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Process MIDIs\n",
        "\n",
        "sorted_or_random_file_loading_order = False # Sorted order is NOT usually recommended\n",
        "dataset_ratio = 1 # Change this if you need more data\n",
        "\n",
        "\n",
        "print('TMIDIX MIDI Processor')\n",
        "print('Starting up...')\n",
        "###########\n",
        "\n",
        "files_count = 0\n",
        "\n",
        "gfiles = []\n",
        "\n",
        "chords_f = []\n",
        "\n",
        "###########\n",
        "\n",
        "print('Loading MIDI files...')\n",
        "print('This may take a while on a large dataset in particular.')\n",
        "\n",
        "dataset_addr = \"./Rock-Piano/\"\n",
        "# os.chdir(dataset_addr)\n",
        "filez = list()\n",
        "for (dirpath, dirnames, filenames) in os.walk(dataset_addr):\n",
        "    filez += [os.path.join(dirpath, file) for file in filenames]\n",
        "print('=' * 70)\n",
        "\n",
        "if filez == []:\n",
        "    print('Could not find any MIDI files. Please check Dataset dir...')\n",
        "    print('=' * 70)\n",
        "\n",
        "if sorted_or_random_file_loading_order:\n",
        "    print('Sorting files...')\n",
        "    filez.sort()\n",
        "    print('Done!')\n",
        "    print('=' * 70)\n",
        "else:\n",
        "    print('Randomizing file list...')\n",
        "    random.shuffle(filez)\n",
        "\n",
        "\n",
        "print('Processing MIDI files. Please wait...')\n",
        "for f in tqdm(filez[:int(len(filez) * dataset_ratio)]):\n",
        "    try:\n",
        "      fn = os.path.basename(f)\n",
        "      fn1 = fn.split('.')[0]\n",
        "\n",
        "      files_count += 1\n",
        "\n",
        "      #print('Loading MIDI file...')\n",
        "      score = TMIDIX.midi2ms_score(open(f, 'rb').read())\n",
        "\n",
        "      itrack = 1\n",
        "\n",
        "      events_matrix1 = []\n",
        "\n",
        "      while itrack < len(score):\n",
        "          for event in score[itrack]:         \n",
        "              if event[0] == 'note':\n",
        "                  events_matrix1.append(event)\n",
        "          itrack += 1\n",
        "\n",
        "      # final processing...\n",
        "\n",
        "      if len(events_matrix1) > 0:\n",
        "\n",
        "          events_matrix1.sort(key=lambda x: x[4], reverse=True) # Sort by pitch H -> L\n",
        "          events_matrix1.sort(key=lambda x: x[1]) # Then sort by start-times\n",
        "          \n",
        "\n",
        "          chords = []\n",
        "          cho = []\n",
        "          pe = events_matrix1[0]\n",
        "          for e in events_matrix1: \n",
        "              if abs(e[1] - pe[1]) == 0:\n",
        "                cho.append(e)\n",
        "              else:\n",
        "                chords.append(cho)\n",
        "                cho = []\n",
        "                cho.append(e)\n",
        "\n",
        "              pe = e\n",
        "\n",
        "      chords_f.append(chords)    \n",
        "\n",
        "      gfiles.append(f)\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print('Saving current progress and quitting...')\n",
        "        break  \n",
        "\n",
        "    except:\n",
        "        print('Bad MIDI:', f)\n",
        "        continue "
      ],
      "metadata": {
        "id": "xiteWj0W5qOr",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Save\n",
        "TMIDIX.Tegridy_Any_Pickle_File_Writer(chords_f, '/content/Rock-Piano-DATA')"
      ],
      "metadata": {
        "id": "rpF5Ms2GHTmA",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prep DATA"
      ],
      "metadata": {
        "id": "DXoMoBCob4f1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load\n",
        "chords_f = TMIDIX.Tegridy_Any_Pickle_File_Reader('/content/Rock-Piano-DATA')"
      ],
      "metadata": {
        "id": "nOfejgSRCQqh",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Process\n",
        "DATA = []\n",
        "\n",
        "for c in tqdm(chords_f):\n",
        "\n",
        "  DATA.extend([127, 512]) # Intro/Zero tokens pair (time == 127, drums pitch == 0+512)\n",
        "\n",
        "  pchord = c[0]\n",
        "\n",
        "  time = 0\n",
        "\n",
        "  for cc in c:\n",
        "\n",
        "    piano_events = [y for y in cc if y[3] == 0]\n",
        "    piano_events_length = len(piano_events)\n",
        "\n",
        "    drums_events = [y for y in cc if y[3] == 9]\n",
        "    drums_events_length = len(drums_events)\n",
        "\n",
        "    time = max(0, min(127, int(abs(cc[0][1] - pchord[0][1]) / 5)))\n",
        "\n",
        "    # Empty (0+) - Pause (128+) - Note (256+) - Chord (384+) == Total of 512 range\n",
        "\n",
        "    # Drums pitches == 512+\n",
        "\n",
        "    # Total of 640 range\n",
        "\n",
        "    if piano_events_length == 0 and drums_events_length != 0: # No piano, drums present (Empty)\n",
        "\n",
        "      for e in drums_events:\n",
        "        if drums_events.index(e) == 0:\n",
        "          DATA.extend([time, e[4]+512])\n",
        "        else:\n",
        "          DATA.extend([0, e[4]+512])\n",
        "\n",
        "    if piano_events_length != 0 and drums_events_length == 0: # Piano present, no drums (Pause)\n",
        "        DATA.extend([time+128, 0+512])\n",
        "\n",
        "    if piano_events_length != 0 and drums_events_length != 0: # Piano note present, drums present (Note)\n",
        "      if piano_events_length == 1:\n",
        "        for e in drums_events:\n",
        "          if drums_events.index(e) == 0:\n",
        "            DATA.extend([time+256, e[4]+512])\n",
        "          else:\n",
        "            DATA.extend([0+256, e[4]+512])\n",
        "\n",
        "    if piano_events_length != 0 and drums_events_length != 0: # Piano chord present, drums present (Chord)\n",
        "      if piano_events_length > 1:\n",
        "        for e in drums_events:\n",
        "          if drums_events.index(e) == 0:\n",
        "            DATA.extend([time+384, e[4]+512])\n",
        "          else:\n",
        "            DATA.extend([0+384, e[4]+512])\n",
        "\n",
        "    pchord = cc"
      ],
      "metadata": {
        "id": "RbWtveNlCgdY",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Save\n",
        "TMIDIX.Tegridy_Any_Pickle_File_Writer(DATA, '/content/Rock-Piano-INTs')"
      ],
      "metadata": {
        "id": "kJ3oK6MJFLp8",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "Eoh4xMiPCWxJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load\n",
        "DATA = TMIDIX.Tegridy_Any_Pickle_File_Reader('/content/Rock-Piano-INTs')\n",
        "train_data1 = DATA"
      ],
      "metadata": {
        "id": "W8Q9-FazYl53",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load processed INTs dataset\n",
        "\n",
        "SEQ_LEN = max_seq\n",
        "\n",
        "BATCH_SIZE = 128 # Change this to your specs\n",
        "\n",
        "# DO NOT FORGET TO ADJUST MODEL PARAMS IN GPT2RGAX module to your specs\n",
        "\n",
        "print('=' * 50)\n",
        "print('Loading training data...')\n",
        "\n",
        "data_train, data_val = torch.LongTensor(train_data1[:-(SEQ_LEN * (BATCH_SIZE))]), torch.LongTensor(train_data1[-(SEQ_LEN * (BATCH_SIZE))-1:])\n",
        "\n",
        "class MusicSamplerDataset(Dataset):\n",
        "    def __init__(self, data, seq_len):\n",
        "        super().__init__()\n",
        "        self.data = data\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        rand = random.randint(0, (self.data.size(0)-self.seq_len) // self.seq_len) * self.seq_len\n",
        "        x = self.data[rand: rand + self.seq_len].long()\n",
        "        trg = self.data[(rand+1): (rand+1) + self.seq_len].long()\n",
        "        return x, trg\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data.size(0)\n",
        "\n",
        "train_dataset = MusicSamplerDataset(data_train, SEQ_LEN)\n",
        "val_dataset   = MusicSamplerDataset(data_val, SEQ_LEN)\n",
        "train_loader  = DataLoader(train_dataset, batch_size = BATCH_SIZE)\n",
        "val_loader    = DataLoader(val_dataset, batch_size = BATCH_SIZE)\n",
        "\n",
        "print('Total INTs in the dataset', len(train_data1))\n",
        "print('Total unique INTs in the dataset', len(set(train_data1)))\n",
        "print('Max INT in the dataset', max(train_data1))\n",
        "print('Min INT in the dataset', min(train_data1))\n",
        "print('=' * 50)\n",
        "\n",
        "print('Length of the dataset:',len(train_dataset))\n",
        "print('Number of dataset samples:', (len(train_dataset) // SEQ_LEN))\n",
        "print('Length of data loader',len(train_loader))\n",
        "print('=' * 50)\n",
        "print('Done! Enjoy! :)')\n",
        "print('=' * 50)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "WqNoNC7MZPiN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Check dataloader for errors\n",
        "for x, trg in train_loader:\n",
        "  print(len(x), len(trg))"
      ],
      "metadata": {
        "id": "E8Rsml9LcH2u",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "_6wXiLoWclWW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Train the model\n",
        "\n",
        "DIC_SIZE = 640\n",
        "\n",
        "# DO NOT FORGET TO ADJUST MODEL PARAMS IN GPT2RGAX module to your specs\n",
        "\n",
        "config = GPTConfig(DIC_SIZE, \n",
        "                   max_seq,\n",
        "                   dim_feedforward=512,\n",
        "                   n_layer=8, \n",
        "                   n_head=8, \n",
        "                   n_embd=512,\n",
        "                   enable_rpr=True,\n",
        "                   er_len=max_seq)\n",
        "\n",
        "# DO NOT FORGET TO ADJUST MODEL PARAMS IN GPT2RGAX module to your specs\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = GPT(config)\n",
        "\n",
        "model = nn.DataParallel(model) # Multi-GPU training...\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "#=====\n",
        "\n",
        "init_step = 0\n",
        "lr = LR_DEFAULT_START\n",
        "lr_stepper = LrStepTracker(d_model, SCHEDULER_WARMUP_STEPS, init_step)\n",
        "eval_loss_func = nn.CrossEntropyLoss(ignore_index=DIC_SIZE)\n",
        "train_loss_func = eval_loss_func\n",
        "\n",
        "opt = Adam(model.parameters(), lr=lr, betas=(ADAM_BETA_1, ADAM_BETA_2), eps=ADAM_EPSILON)\n",
        "lr_scheduler = LambdaLR(opt, lr_stepper.step)\n",
        "\n",
        "\n",
        "#===\n",
        "\n",
        "best_eval_acc        = 0.0\n",
        "best_eval_acc_epoch  = -1\n",
        "best_eval_loss       = float(\"inf\")\n",
        "best_eval_loss_epoch = -1\n",
        "best_acc_file = '/content/gpt2_rpr_acc.pth'\n",
        "best_loss_file = '/content/gpt2_rpr_loss.pth'\n",
        "loss_train, loss_val, acc_val = [], [], []\n",
        "\n",
        "for epoch in range(0, epochs):\n",
        "    new_best = False\n",
        "    \n",
        "    loss = train(epoch+1, \n",
        "                 model, train_loader, \n",
        "                 train_loss_func, \n",
        "                 opt, \n",
        "                 lr_scheduler, \n",
        "                 num_iters=-1, \n",
        "                 save_checkpoint_steps=4000)\n",
        "    \n",
        "    loss_train.append(loss)\n",
        "    \n",
        "    eval_loss, eval_acc = eval_model(model, val_loader, eval_loss_func, num_iters=-1)\n",
        "    loss_val.append(eval_loss)\n",
        "    acc_val.append(eval_acc)\n",
        "    \n",
        "    if(eval_acc > best_eval_acc):\n",
        "        best_eval_acc = eval_acc\n",
        "        best_eval_acc_epoch  = epoch+1\n",
        "        torch.save(model.state_dict(), best_acc_file)\n",
        "        new_best = True\n",
        "\n",
        "    if(eval_loss < best_eval_loss):\n",
        "        best_eval_loss       = eval_loss\n",
        "        best_eval_loss_epoch = epoch+1\n",
        "        torch.save(model.state_dict(), best_loss_file)\n",
        "        new_best = True\n",
        "    \n",
        "    if(new_best):\n",
        "        print(\"Best eval acc epoch:\", best_eval_acc_epoch)\n",
        "        print(\"Best eval acc:\", best_eval_acc)\n",
        "        print(\"\")\n",
        "        print(\"Best eval loss epoch:\", best_eval_loss_epoch)\n",
        "        print(\"Best eval loss:\", best_eval_loss)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "WPTGeP8ZZ_Hr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (MODEL SAVE/LOAD)"
      ],
      "metadata": {
        "id": "M23QeLsxrxDh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Save the model\n",
        "\n",
        "print('Saving the model...')\n",
        "full_path_to_model_checkpoint = \"/content/Piano-Drummer-Trained-Model.pth\" #@param {type:\"string\"}\n",
        "torch.save(model.state_dict(), full_path_to_model_checkpoint)\n",
        "print('Done!')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ZwBm-VP8sAH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load/Reload the model\n",
        "\n",
        "full_path_to_model_checkpoint = \"/content/Piano_Drummer_Trained_Model_116000_steps_0.6056_loss.pth\" #@param {type:\"string\"}\n",
        "\n",
        "print('Loading the model...')\n",
        "config = GPTConfig(640, \n",
        "                   384,\n",
        "                   dim_feedforward=640,\n",
        "                   n_layer=16, \n",
        "                   n_head=16, \n",
        "                   n_embd=640,\n",
        "                   enable_rpr=True,\n",
        "                   er_len=384)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = GPT(config)\n",
        "\n",
        "state_dict = torch.load(full_path_to_model_checkpoint, map_location=device)\n",
        "\n",
        "new_state_dict = OrderedDict()\n",
        "for k, v in state_dict.items():\n",
        "    name = k[7:] #remove 'module'\n",
        "    new_state_dict[name] = v\n",
        "\n",
        "model.load_state_dict(new_state_dict)\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "model.eval()\n",
        "\n",
        "print('Done!')\n",
        "\n",
        "summary(model)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ENezD96IsBbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate"
      ],
      "metadata": {
        "id": "SeXXGIHDZu4v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load source piano composition\n",
        "\n",
        "full_path_to_custom_MIDI = \"/content/tegridy-tools/tegridy-tools/seed2.mid\"\n",
        "print('Loading custom MIDI file...')\n",
        "\n",
        "score = TMIDIX.midi2ms_score(open(full_path_to_custom_MIDI, 'rb').read())\n",
        "\n",
        "events_matrix1 = []\n",
        "\n",
        "itrack = 1\n",
        "\n",
        "while itrack < len(score):\n",
        "    for event in score[itrack]:         \n",
        "        if event[0] == 'note' and event[3] != 9:\n",
        "            events_matrix1.append(event)\n",
        "    itrack += 1\n",
        "\n",
        "\n",
        "events_matrix1.sort(key=lambda x: x[4], reverse=True) # Sort by pitch H -> L\n",
        "events_matrix1.sort(key=lambda x: x[1]) # Then sort by start-times\n",
        "\n",
        "if len(events_matrix1) > 0:\n",
        "\n",
        "    # recalculating timings\n",
        "\n",
        "    for e in events_matrix1:\n",
        "        e[1] = int(e[1] / 5)\n",
        "        e[2] = int(e[2] / 10)\n",
        "    \n",
        "    # final processing...\n",
        "    melody_chords = []\n",
        "    \n",
        "    pe = events_matrix1[0]\n",
        "\n",
        "    for e in events_matrix1:\n",
        "\n",
        "        time = max(0, min(127, e[1]-pe[1])) # Time-shift\n",
        "        dur = max(0, min(127, e[2])) # Duration\n",
        "        ptc = max(0, min(127, e[4])) # Pitch\n",
        "        vel = max(0, min(127, e[5]))\n",
        "\n",
        "        melody_chords.append([time, dur, ptc, vel])\n",
        "\n",
        "        pe = e\n",
        "\n",
        "ctimes = []\n",
        "       \n",
        "chords = []\n",
        "cho = []\n",
        "for m in melody_chords:\n",
        "  if m[0] == 0:\n",
        "    cho.append(m)\n",
        "  else:\n",
        "    chords.append(cho)\n",
        "\n",
        "    if len(cho) == 1:\n",
        "      ctimes.append(cho[0][0]+256)\n",
        "    else:\n",
        "      ctimes.append(cho[0][0]+384)\n",
        "\n",
        "\n",
        "    cho = []\n",
        "    cho.append(m)\n",
        "\n",
        "print('Done!')        "
      ],
      "metadata": {
        "id": "e4yEVRggsYyY",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple Generator"
      ],
      "metadata": {
        "id": "9GD5z0McZwX3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "out = [ctimes[0]]\n",
        "\n",
        "drums1 = []\n",
        "\n",
        "for i in tqdm(range(len(ctimes)-1)):\n",
        "\n",
        "  rand_seq = model.generate(torch.Tensor(out[-383:]), \n",
        "                                        target_seq_length=len(out[-383:])+1,\n",
        "                                        temperature=1,\n",
        "                                        stop_token=640,\n",
        "                                        verbose=False)\n",
        "\n",
        "  out1 = rand_seq[0].cpu().numpy().tolist()\n",
        "  out.append(out1[-1])\n",
        "  drums1.append(out1[-1])\n",
        "  out.append(ctimes[i+1])\n",
        "\n",
        "song = chords[:-1]\n",
        "song_f = []\n",
        "time = 0\n",
        "dur = 0\n",
        "vel = 0\n",
        "pitch = 0\n",
        "channel = 0\n",
        "son = []\n",
        "idx = 0\n",
        "for s in song:\n",
        "  time += s[0][0] * 5\n",
        "  for ss in s:\n",
        "\n",
        "    \n",
        "\n",
        "    dur = ((ss[1]) * 10) + 10\n",
        "    \n",
        "    channel = 0 # Piano\n",
        "\n",
        "    pitch = ss[2]\n",
        "    \n",
        "    vel = ss[3] # Note velocity == note pitch value\n",
        "\n",
        "                        \n",
        "    song_f.append(['note', time, dur, channel, pitch, vel ])\n",
        "    \n",
        "  channel = 9 # Drums\n",
        "\n",
        "  pitch = drums1[idx] - 512\n",
        "\n",
        "  song_f.append(['note', time, dur, channel, pitch, 90 ])\n",
        "\n",
        "  idx += 1\n",
        "\n",
        "detailed_stats = TMIDIX.Tegridy_SONG_to_MIDI_Converter(song_f,\n",
        "                                                    output_signature = 'Piano Drummer',  \n",
        "                                                    output_file_name = '/content/Piano-Drummer-Music-Composition', \n",
        "                                                    track_name='Project Los Angeles',\n",
        "                                                    list_of_MIDI_patches=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "                                                    number_of_ticks_per_quarter=500)\n",
        "\n",
        "print('Done!')"
      ],
      "metadata": {
        "id": "az9tLj-bvy2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Advanced Generator"
      ],
      "metadata": {
        "id": "kgwZ7chrQrm0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Working"
      ],
      "metadata": {
        "id": "RH48mSIWvpnw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "number_of_tokens_per_note = 11 # Must be odd for now...\n",
        "number_of_memory_tokens = 128 # Must be even for now\n",
        "time_k = 0\n",
        "model_temperature = 1\n",
        "\n",
        "out = copy.deepcopy([ctimes[0]])\n",
        "\n",
        "test = []\n",
        "\n",
        "for i in tqdm(range(len(ctimes)-1)):\n",
        "\n",
        "    rand_seq = model.generate(torch.Tensor(out[-(number_of_memory_tokens-1):]), \n",
        "                                          target_seq_length=(len(out[-(number_of_memory_tokens-1):])+number_of_tokens_per_note),\n",
        "                                          temperature=model_temperature,\n",
        "                                          stop_token=640,\n",
        "                                          verbose=False)\n",
        "\n",
        "    out1 = rand_seq[0].cpu().numpy().tolist()\n",
        "\n",
        "    time = 0\n",
        "    next = ctimes[i+1] % 128\n",
        "    k = ctimes[i+1] // 128\n",
        "    count = 0\n",
        "    tdelta = ctimes[i+1] % 128\n",
        "\n",
        "    for j in [y % 128 for y in out1[-(number_of_tokens_per_note-1):][0::2]]:\n",
        "      \n",
        "      time += j\n",
        "      \n",
        "      if time+time_k >= next:\n",
        "        break\n",
        "\n",
        "      tdelta = next - time  \n",
        "      count += 1\n",
        "\n",
        "    out.extend(out1[-(number_of_tokens_per_note):][:(count*2)+1])\n",
        "\n",
        "    out.append(((k * 128) + tdelta))\n",
        "\n",
        "    test.append(out1[-(number_of_tokens_per_note):][:(count*2)+1])\n",
        "\n",
        "song = chords\n",
        "song_f = []\n",
        "time = 0\n",
        "dur = 0\n",
        "vel = 0\n",
        "pitch = 0\n",
        "channel = 0\n",
        "\n",
        "count = 0\n",
        "for s in song:\n",
        "\n",
        "  time += (ctimes[count] % 128) * 5\n",
        "  count += 1\n",
        "  for ss in s:\n",
        "\n",
        "    dur = ((ss[1]) * 10) + 10\n",
        "    \n",
        "    channel = 0 # Piano\n",
        "\n",
        "    pitch = ss[2]\n",
        "    \n",
        "    vel = ss[3] # Note velocity == note pitch value\n",
        "\n",
        "                        \n",
        "    song_f.append(['note', time, dur, channel, pitch, vel ])\n",
        "\n",
        "time = 0\n",
        "dur = 0\n",
        "idx = 0\n",
        "\n",
        "for c in ctimes[:-1]:\n",
        "  time += (c % 128) * 5\n",
        "  time1 = time\n",
        "\n",
        "  for t in test[idx]:\n",
        "    if t < 512:\n",
        "      time1 += (t % 128) * 5\n",
        "      dur = ((t % 128) * 10) + 10\n",
        "      \n",
        "    else:\n",
        "      if t > 512:\n",
        "        \n",
        "        channel = 9 # Drums\n",
        "\n",
        "        pitch = t - 512\n",
        "\n",
        "        vel = 90\n",
        "\n",
        "        song_f.append(['note', time1, dur, channel, pitch, 90 ])\n",
        "  idx += 1\n",
        "song_f.sort(key=lambda x: x[1])\n",
        "\n",
        "detailed_stats = TMIDIX.Tegridy_SONG_to_MIDI_Converter(song_f,\n",
        "                                                    output_signature = 'Piano Drummer',  \n",
        "                                                    output_file_name = '/content/Piano-Drummer-Music-Composition', \n",
        "                                                    track_name='Project Los Angeles',\n",
        "                                                    list_of_MIDI_patches=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "                                                    number_of_ticks_per_quarter=500)\n",
        "\n",
        "print('Done!')"
      ],
      "metadata": {
        "id": "JuIxFhNzm2_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Colab MIDI player and plotter"
      ],
      "metadata": {
        "id": "VmrfiXy0avY9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Displaying resulting composition...')\n",
        "fname = '/content/Piano-Drummer-Music-Composition'\n",
        "\n",
        "pm = pretty_midi.PrettyMIDI(fname + '.mid')\n",
        "\n",
        "# Retrieve piano roll of the MIDI file\n",
        "piano_roll = pm.get_piano_roll()\n",
        "\n",
        "plt.figure(figsize=(14, 5))\n",
        "librosa.display.specshow(piano_roll, x_axis='time', y_axis='cqt_note', fmin=1, hop_length=160, sr=16000, cmap=plt.cm.hot)\n",
        "plt.title(fname)\n",
        "\n",
        "FluidSynth(\"/usr/share/sounds/sf2/FluidR3_GM.sf2\", 16000).midi_to_audio(str(fname + '.mid'), str(fname + '.wav'))\n",
        "Audio(str(fname + '.wav'), rate=16000)"
      ],
      "metadata": {
        "id": "WGBAJyUpazXN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}